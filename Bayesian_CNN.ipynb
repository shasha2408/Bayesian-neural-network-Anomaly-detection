{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hjmdX-HbWdeI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18398, 54)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>y</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>...</th>\n",
              "      <th>x49</th>\n",
              "      <th>x50</th>\n",
              "      <th>x51</th>\n",
              "      <th>x52</th>\n",
              "      <th>x53</th>\n",
              "      <th>x54</th>\n",
              "      <th>x55</th>\n",
              "      <th>x56</th>\n",
              "      <th>x58</th>\n",
              "      <th>x60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1999-05-01 00:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.376665</td>\n",
              "      <td>-4.596435</td>\n",
              "      <td>-4.095756</td>\n",
              "      <td>13.497687</td>\n",
              "      <td>-0.118830</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>-0.061114</td>\n",
              "      <td>-0.059966</td>\n",
              "      <td>...</td>\n",
              "      <td>10.210182</td>\n",
              "      <td>11.295155</td>\n",
              "      <td>29.984624</td>\n",
              "      <td>10.091721</td>\n",
              "      <td>0.053279</td>\n",
              "      <td>-4.936434</td>\n",
              "      <td>-24.590146</td>\n",
              "      <td>18.515436</td>\n",
              "      <td>0.033444</td>\n",
              "      <td>0.006076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999-05-01 00:02:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.475720</td>\n",
              "      <td>-4.542502</td>\n",
              "      <td>-4.018359</td>\n",
              "      <td>16.230659</td>\n",
              "      <td>-0.128733</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>-0.061114</td>\n",
              "      <td>-0.059966</td>\n",
              "      <td>...</td>\n",
              "      <td>12.534340</td>\n",
              "      <td>11.290761</td>\n",
              "      <td>29.984624</td>\n",
              "      <td>10.095871</td>\n",
              "      <td>0.062801</td>\n",
              "      <td>-4.937179</td>\n",
              "      <td>-32.413266</td>\n",
              "      <td>22.760065</td>\n",
              "      <td>0.033536</td>\n",
              "      <td>0.006083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999-05-01 00:04:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.363848</td>\n",
              "      <td>-4.681394</td>\n",
              "      <td>-4.353147</td>\n",
              "      <td>14.127997</td>\n",
              "      <td>-0.138636</td>\n",
              "      <td>0.010803</td>\n",
              "      <td>-0.061114</td>\n",
              "      <td>-0.030057</td>\n",
              "      <td>...</td>\n",
              "      <td>18.582893</td>\n",
              "      <td>11.286366</td>\n",
              "      <td>29.984624</td>\n",
              "      <td>10.100265</td>\n",
              "      <td>0.072322</td>\n",
              "      <td>-4.937924</td>\n",
              "      <td>-34.183774</td>\n",
              "      <td>27.004663</td>\n",
              "      <td>0.033629</td>\n",
              "      <td>0.006090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1999-05-01 00:06:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.301590</td>\n",
              "      <td>-4.758934</td>\n",
              "      <td>-4.023612</td>\n",
              "      <td>13.161566</td>\n",
              "      <td>-0.148142</td>\n",
              "      <td>0.002075</td>\n",
              "      <td>-0.061114</td>\n",
              "      <td>-0.019986</td>\n",
              "      <td>...</td>\n",
              "      <td>17.719032</td>\n",
              "      <td>11.281972</td>\n",
              "      <td>29.984624</td>\n",
              "      <td>10.104660</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>-4.938669</td>\n",
              "      <td>-35.954281</td>\n",
              "      <td>21.672449</td>\n",
              "      <td>0.033721</td>\n",
              "      <td>0.006097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1999-05-01 00:08:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.265578</td>\n",
              "      <td>-4.749928</td>\n",
              "      <td>-4.333150</td>\n",
              "      <td>15.267340</td>\n",
              "      <td>-0.155314</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>-0.061114</td>\n",
              "      <td>-0.030057</td>\n",
              "      <td>...</td>\n",
              "      <td>16.855202</td>\n",
              "      <td>11.277577</td>\n",
              "      <td>29.984624</td>\n",
              "      <td>10.109054</td>\n",
              "      <td>0.091121</td>\n",
              "      <td>-4.939414</td>\n",
              "      <td>-37.724789</td>\n",
              "      <td>21.907251</td>\n",
              "      <td>0.033777</td>\n",
              "      <td>0.006105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  time  y        x1        x2        x3         x4        x5  \\\n",
              "0  1999-05-01 00:00:00  0  0.376665 -4.596435 -4.095756  13.497687 -0.118830   \n",
              "1  1999-05-01 00:02:00  0  0.475720 -4.542502 -4.018359  16.230659 -0.128733   \n",
              "2  1999-05-01 00:04:00  0  0.363848 -4.681394 -4.353147  14.127997 -0.138636   \n",
              "3  1999-05-01 00:06:00  0  0.301590 -4.758934 -4.023612  13.161566 -0.148142   \n",
              "4  1999-05-01 00:08:00  0  0.265578 -4.749928 -4.333150  15.267340 -0.155314   \n",
              "\n",
              "         x7        x8        x9  ...        x49        x50        x51  \\\n",
              "0  0.000732 -0.061114 -0.059966  ...  10.210182  11.295155  29.984624   \n",
              "1  0.000732 -0.061114 -0.059966  ...  12.534340  11.290761  29.984624   \n",
              "2  0.010803 -0.061114 -0.030057  ...  18.582893  11.286366  29.984624   \n",
              "3  0.002075 -0.061114 -0.019986  ...  17.719032  11.281972  29.984624   \n",
              "4  0.000732 -0.061114 -0.030057  ...  16.855202  11.277577  29.984624   \n",
              "\n",
              "         x52       x53       x54        x55        x56       x58       x60  \n",
              "0  10.091721  0.053279 -4.936434 -24.590146  18.515436  0.033444  0.006076  \n",
              "1  10.095871  0.062801 -4.937179 -32.413266  22.760065  0.033536  0.006083  \n",
              "2  10.100265  0.072322 -4.937924 -34.183774  27.004663  0.033629  0.006090  \n",
              "3  10.104660  0.081600 -4.938669 -35.954281  21.672449  0.033721  0.006097  \n",
              "4  10.109054  0.091121 -4.939414 -37.724789  21.907251  0.033777  0.006105  \n",
              "\n",
              "[5 rows x 54 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as keras\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "df = pd.read_csv(R'C:\\Users\\Dell\\Desktop\\New folder (2)\\Flipout\\cleaned.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train count: 14718 Test count: 3680\n"
          ]
        }
      ],
      "source": [
        "x = df.iloc[:,2:]\n",
        "Y = df.y.astype(int)\n",
        "sd = StandardScaler()\n",
        "df_new = pd.DataFrame(sd.fit_transform(x), columns=x.columns, index=x.index)\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_new,Y,train_size = 0.80, random_state = 42)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_COUNT = len(y_train)\n",
        "TEST_COUNT = len(y_test)\n",
        "BATCHES_PER_EPOCH = TRAIN_COUNT // BATCH_SIZE\n",
        "TEST_BATCHES_PER_EPOCH = TEST_COUNT // BATCH_SIZE\n",
        "INPUT_SIZE = np.shape(x_train)[1]\n",
        "\n",
        "print('Train count:', TRAIN_COUNT, 'Test count:', TEST_COUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x2Q8Cy8HZ8dB"
      },
      "source": [
        "### Input Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uiTIHzr5Wsmn"
      },
      "outputs": [],
      "source": [
        "def combined_dataset(features, labels):\n",
        "    assert features.shape[0] == labels.shape[0]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((np.expand_dims(features, axis=-1), labels))\n",
        "    return dataset\n",
        "\n",
        "# For training\n",
        "def train_input_fn():\n",
        "    dataset = combined_dataset(x_train, y_train)\n",
        "    return dataset.shuffle(TEST_COUNT, reshuffle_each_iteration=True).repeat().batch(BATCH_SIZE, drop_remainder=True).prefetch(1)\n",
        "\n",
        "# For evaluation and metrics\n",
        "def eval_input_fn():\n",
        "    dataset = combined_dataset(x_test, y_test)\n",
        "    return dataset.repeat().batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "training_batches = train_input_fn()\n",
        "training_iterator = tf.compat.v1.data.make_one_shot_iterator(training_batches)\n",
        "heldout_iterator = tf.compat.v1.data.make_one_shot_iterator(eval_input_fn())\n",
        "\n",
        "# Combine these into a feedable iterator that can switch between training\n",
        "# and validation inputs.\n",
        "handle = tf.compat.v1.placeholder(tf.string, shape=[])\n",
        "feedable_iterator = tf.compat.v1.data.Iterator.from_string_handle(handle, tf.compat.v1.data.get_output_types(training_batches),\n",
        "                                           tf.compat.v1.data.get_output_shapes(training_batches))\n",
        "# feedable_iterator = tf.compat.v1.data.Iterator.from_string_handle(handle, training_batches.output_types, training_batches.output_shapes)\n",
        "series, labels = feedable_iterator.get_next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PnGsC48GaGTk"
      },
      "source": [
        "\n",
        "#### Bayesian CNN Model\n",
        "\n",
        "\n",
        "Model consists of:\n",
        "* An initial 1-D convolutional layer\n",
        "* 5 repeated residual blocks (`same` padding)\n",
        "* A fully-connected layer\n",
        "* A linear layer with softmax output\n",
        "* Flipout layers are used instead of standard layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Q8XdxTVYaO1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"bayes_cnn_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_32 (InputLayer)          [(None, 52, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " conv1d_flipout_31 (Conv1DFlipo  (None, 48, 32)      352         ['input_32[0][0]']               \n",
            " ut)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_1 (Conv1DFlipout)        (None, 48, 32)       10272       ['conv1d_flipout_31[0][0]']      \n",
            "                                                                                                  \n",
            " Conv2_1 (Conv1DFlipout)        (None, 48, 32)       10272       ['Conv1_1[0][0]']                \n",
            "                                                                                                  \n",
            " ResidualSum_1 (Add)            (None, 48, 32)       0           ['Conv2_1[0][0]',                \n",
            "                                                                  'conv1d_flipout_31[0][0]']      \n",
            "                                                                                                  \n",
            " Act_1 (Activation)             (None, 48, 32)       0           ['ResidualSum_1[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool_1 (MaxPooling1D)       (None, 24, 32)       0           ['Act_1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_2 (Conv1DFlipout)        (None, 24, 32)       10272       ['MaxPool_1[0][0]']              \n",
            "                                                                                                  \n",
            " Conv2_2 (Conv1DFlipout)        (None, 24, 32)       10272       ['Conv1_2[0][0]']                \n",
            "                                                                                                  \n",
            " ResidualSum_2 (Add)            (None, 24, 32)       0           ['Conv2_2[0][0]',                \n",
            "                                                                  'MaxPool_1[0][0]']              \n",
            "                                                                                                  \n",
            " Act_2 (Activation)             (None, 24, 32)       0           ['ResidualSum_2[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool_2 (MaxPooling1D)       (None, 12, 32)       0           ['Act_2[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_3 (Conv1DFlipout)        (None, 12, 32)       10272       ['MaxPool_2[0][0]']              \n",
            "                                                                                                  \n",
            " Conv2_3 (Conv1DFlipout)        (None, 12, 32)       10272       ['Conv1_3[0][0]']                \n",
            "                                                                                                  \n",
            " ResidualSum_3 (Add)            (None, 12, 32)       0           ['Conv2_3[0][0]',                \n",
            "                                                                  'MaxPool_2[0][0]']              \n",
            "                                                                                                  \n",
            " Act_3 (Activation)             (None, 12, 32)       0           ['ResidualSum_3[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool_3 (MaxPooling1D)       (None, 6, 32)        0           ['Act_3[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_4 (Conv1DFlipout)        (None, 6, 32)        10272       ['MaxPool_3[0][0]']              \n",
            "                                                                                                  \n",
            " Conv2_4 (Conv1DFlipout)        (None, 6, 32)        10272       ['Conv1_4[0][0]']                \n",
            "                                                                                                  \n",
            " ResidualSum_4 (Add)            (None, 6, 32)        0           ['Conv2_4[0][0]',                \n",
            "                                                                  'MaxPool_3[0][0]']              \n",
            "                                                                                                  \n",
            " Act_4 (Activation)             (None, 6, 32)        0           ['ResidualSum_4[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool_4 (MaxPooling1D)       (None, 3, 32)        0           ['Act_4[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_5 (Conv1DFlipout)        (None, 3, 32)        10272       ['MaxPool_4[0][0]']              \n",
            "                                                                                                  \n",
            " Conv2_5 (Conv1DFlipout)        (None, 3, 32)        10272       ['Conv1_5[0][0]']                \n",
            "                                                                                                  \n",
            " ResidualSum_5 (Add)            (None, 3, 32)        0           ['Conv2_5[0][0]',                \n",
            "                                                                  'MaxPool_4[0][0]']              \n",
            "                                                                                                  \n",
            " Act_5 (Activation)             (None, 3, 32)        0           ['ResidualSum_5[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool_5 (MaxPooling1D)       (None, 1, 32)        0           ['Act_5[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten_19 (Flatten)           (None, 32)           0           ['MaxPool_5[0][0]']              \n",
            "                                                                                                  \n",
            " FC1 (DenseFlipout)             (None, 32)           2080        ['flatten_19[0][0]']             \n",
            "                                                                                                  \n",
            " Output (DenseFlipout)          (None, 2)            130         ['FC1[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 105,282\n",
            "Trainable params: 105,282\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#  It is a scheduling technique designed to prevent posterior collapse among autoregressive VAEs.\n",
        "# At the beginning of learning, the beta value is reduced to force the latent z to contain meaningful information,\n",
        "# and the beta value is gradually increased to match the prior.\n",
        "KL_ANNEALING = 30\n",
        "\n",
        "MODEL_PATH = r'C:\\Users\\Dell\\Desktop\\New folder (2)\\Flipout\\model'\n",
        "\n",
        "def kernel_prior(dtype, shape, name, trainable, add_variable_fn):\n",
        "    return tfp.layers.default_multivariate_normal_fn(dtype, shape, name, trainable, add_variable_fn)\n",
        "\n",
        "def conv_unit(unit, input_layer):\n",
        "    s = '_' + str(unit)\n",
        "    layer = tfp.layers.Convolution1DFlipout(name='Conv1' + s, filters=32, kernel_size=5, strides=1, padding='same', activation='relu', kernel_prior_fn=kernel_prior)(input_layer)\n",
        "    layer = tfp.layers.Convolution1DFlipout(name='Conv2' + s, filters=32, kernel_size=5, strides=1, padding='same', activation=None, kernel_prior_fn=kernel_prior)(layer )\n",
        "    layer = keras.Add(name='ResidualSum' + s)([layer, input_layer])\n",
        "    layer = keras.Activation(\"relu\", name='Act' + s)(layer)\n",
        "    layer = keras.MaxPooling1D(name='MaxPool' + s, pool_size=2, strides=2)(layer)\n",
        "    return layer\n",
        "\n",
        "def model_fn(input_shape):\n",
        "    time_series = tf.keras.layers.Input(shape=input_shape, dtype='float32')\n",
        "    \n",
        "    current_layer = tfp.layers.Convolution1DFlipout(filters=32, kernel_size=5, strides=1, kernel_prior_fn=kernel_prior)(time_series)\n",
        "\n",
        "    for i in range(5):\n",
        "        current_layer = conv_unit(i + 1, current_layer)\n",
        "\n",
        "    current_layer = keras.Flatten()(current_layer)\n",
        "    current_layer = tfp.layers.DenseFlipout(32, name='FC1', activation='relu', kernel_prior_fn=kernel_prior)(current_layer)\n",
        "    logits = tfp.layers.DenseFlipout(2, name='Output', kernel_prior_fn=kernel_prior)(current_layer)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=time_series, outputs=logits, name='bayes_cnn_model')\n",
        "    return model\n",
        "  \n",
        "# Compute the negative Evidence Lower Bound (ELBO) loss\n",
        "t = tf.compat.v1.Variable(0.0)\n",
        "\n",
        "def loss_fn(labels, logits):\n",
        "    labels_distribution = tfd.Categorical(logits=logits)\n",
        "\n",
        "    # Perform KL annealing. The optimal number of annealing steps\n",
        "    # depends on the dataset and architecture.\n",
        "    kl_regularizer = t / (KL_ANNEALING * BATCHES_PER_EPOCH)\n",
        "\n",
        "    # Compute the -ELBO as the loss. The kl term is annealed from 0 to 1 over\n",
        "    # the epochs specified by the kl_annealing flag.\n",
        "    log_likelihood = labels_distribution.log_prob(labels)\n",
        "    neg_log_likelihood = -tf.reduce_mean(input_tensor=log_likelihood)\n",
        "    kl = sum(model.losses) / len(x_train) * tf.minimum(1.0, kl_regularizer)\n",
        "    return neg_log_likelihood + kl, kl, kl_regularizer, labels_distribution\n",
        "\n",
        "model = model_fn([INPUT_SIZE,1])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1h96cjFraUo_"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9uHtgxoLynkU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Loss: 0.416 Accuracy: 0.500 KL: 0.003 KL-reg: 0.000\n",
            "   Loss: 0.129 Accuracy: 0.979 KL: 0.121 KL-reg: 0.007\n",
            "   Loss: 0.251 Accuracy: 0.987 KL: 0.238 KL-reg: 0.013\n",
            "   Loss: 0.376 Accuracy: 0.988 KL: 0.355 KL-reg: 0.020\n",
            "   Loss: 0.481 Accuracy: 0.990 KL: 0.471 KL-reg: 0.026\n",
            "   Loss: 0.896 Accuracy: 0.990 KL: 0.586 KL-reg: 0.033\n",
            "Epoch:   1 Validation Accuracy: 0.994\n",
            "   Loss: 0.708 Accuracy: 0.991 KL: 0.700 KL-reg: 0.039\n",
            "   Loss: 0.817 Accuracy: 0.991 KL: 0.813 KL-reg: 0.046\n",
            "   Loss: 0.936 Accuracy: 0.991 KL: 0.925 KL-reg: 0.052\n",
            "   Loss: 1.114 Accuracy: 0.991 KL: 1.035 KL-reg: 0.059\n",
            "   Loss: 1.151 Accuracy: 0.992 KL: 1.143 KL-reg: 0.066\n",
            "Epoch:   2 Validation Accuracy: 0.994\n",
            "   Loss: 1.254 Accuracy: 0.992 KL: 1.249 KL-reg: 0.072\n",
            "   Loss: 1.362 Accuracy: 0.992 KL: 1.353 KL-reg: 0.079\n",
            "   Loss: 1.462 Accuracy: 0.992 KL: 1.456 KL-reg: 0.085\n",
            "   Loss: 1.648 Accuracy: 0.992 KL: 1.556 KL-reg: 0.092\n",
            "   Loss: 1.722 Accuracy: 0.992 KL: 1.655 KL-reg: 0.098\n",
            "Epoch:   3 Validation Accuracy: 0.994\n",
            "   Loss: 1.756 Accuracy: 0.992 KL: 1.752 KL-reg: 0.105\n",
            "   Loss: 1.879 Accuracy: 0.992 KL: 1.846 KL-reg: 0.111\n",
            "   Loss: 1.946 Accuracy: 0.992 KL: 1.940 KL-reg: 0.118\n",
            "   Loss: 2.041 Accuracy: 0.992 KL: 2.031 KL-reg: 0.124\n",
            "   Loss: 2.141 Accuracy: 0.992 KL: 2.119 KL-reg: 0.131\n",
            "Epoch:   4 Validation Accuracy: 0.994\n",
            "   Loss: 2.303 Accuracy: 0.992 KL: 2.205 KL-reg: 0.138\n",
            "   Loss: 2.296 Accuracy: 0.993 KL: 2.290 KL-reg: 0.144\n",
            "   Loss: 2.380 Accuracy: 0.992 KL: 2.372 KL-reg: 0.151\n",
            "   Loss: 2.559 Accuracy: 0.992 KL: 2.452 KL-reg: 0.157\n",
            "   Loss: 2.650 Accuracy: 0.992 KL: 2.529 KL-reg: 0.164\n",
            "Epoch:   5 Validation Accuracy: 0.994\n",
            "   Loss: 2.622 Accuracy: 0.992 KL: 2.603 KL-reg: 0.170\n",
            "   Loss: 2.683 Accuracy: 0.993 KL: 2.675 KL-reg: 0.177\n",
            "   Loss: 2.858 Accuracy: 0.993 KL: 2.745 KL-reg: 0.183\n",
            "   Loss: 2.913 Accuracy: 0.993 KL: 2.814 KL-reg: 0.190\n",
            "   Loss: 2.967 Accuracy: 0.993 KL: 2.879 KL-reg: 0.196\n",
            "Epoch:   6 Validation Accuracy: 0.994\n",
            "   Loss: 3.086 Accuracy: 0.993 KL: 2.942 KL-reg: 0.203\n",
            "   Loss: 3.010 Accuracy: 0.993 KL: 3.002 KL-reg: 0.210\n",
            "   Loss: 3.066 Accuracy: 0.993 KL: 3.061 KL-reg: 0.216\n",
            "   Loss: 3.127 Accuracy: 0.993 KL: 3.117 KL-reg: 0.223\n",
            "   Loss: 3.201 Accuracy: 0.993 KL: 3.172 KL-reg: 0.229\n",
            "Epoch:   7 Validation Accuracy: 0.994\n",
            "   Loss: 3.231 Accuracy: 0.993 KL: 3.224 KL-reg: 0.236\n",
            "   Loss: 3.295 Accuracy: 0.993 KL: 3.276 KL-reg: 0.242\n",
            "   Loss: 3.333 Accuracy: 0.993 KL: 3.327 KL-reg: 0.249\n",
            "   Loss: 3.463 Accuracy: 0.993 KL: 3.375 KL-reg: 0.255\n",
            "   Loss: 3.446 Accuracy: 0.993 KL: 3.421 KL-reg: 0.262\n",
            "Epoch:   8 Validation Accuracy: 0.994\n",
            "   Loss: 3.481 Accuracy: 0.993 KL: 3.465 KL-reg: 0.268\n",
            "   Loss: 3.515 Accuracy: 0.993 KL: 3.509 KL-reg: 0.275\n",
            "   Loss: 3.552 Accuracy: 0.993 KL: 3.550 KL-reg: 0.282\n",
            "   Loss: 3.598 Accuracy: 0.993 KL: 3.590 KL-reg: 0.288\n",
            "   Loss: 3.738 Accuracy: 0.993 KL: 3.629 KL-reg: 0.295\n",
            "Epoch:   9 Validation Accuracy: 0.994\n",
            "   Loss: 3.669 Accuracy: 0.993 KL: 3.666 KL-reg: 0.301\n",
            "   Loss: 3.818 Accuracy: 0.993 KL: 3.702 KL-reg: 0.308\n",
            "   Loss: 3.749 Accuracy: 0.993 KL: 3.738 KL-reg: 0.314\n",
            "   Loss: 3.782 Accuracy: 0.993 KL: 3.773 KL-reg: 0.321\n",
            "   Loss: 3.813 Accuracy: 0.993 KL: 3.806 KL-reg: 0.327\n",
            "Epoch:  10 Validation Accuracy: 0.994\n",
            "   Loss: 3.910 Accuracy: 0.993 KL: 3.838 KL-reg: 0.334\n",
            "   Loss: 3.876 Accuracy: 0.993 KL: 3.870 KL-reg: 0.340\n",
            "   Loss: 3.931 Accuracy: 0.993 KL: 3.902 KL-reg: 0.347\n",
            "   Loss: 3.951 Accuracy: 0.993 KL: 3.933 KL-reg: 0.354\n",
            "   Loss: 3.974 Accuracy: 0.993 KL: 3.964 KL-reg: 0.360\n",
            "Epoch:  11 Validation Accuracy: 0.994\n",
            "   Loss: 4.001 Accuracy: 0.993 KL: 3.994 KL-reg: 0.367\n",
            "   Loss: 4.039 Accuracy: 0.993 KL: 4.025 KL-reg: 0.373\n",
            "   Loss: 4.069 Accuracy: 0.993 KL: 4.056 KL-reg: 0.380\n",
            "   Loss: 4.096 Accuracy: 0.993 KL: 4.086 KL-reg: 0.386\n",
            "   Loss: 4.119 Accuracy: 0.993 KL: 4.116 KL-reg: 0.393\n",
            "   Loss: 4.151 Accuracy: 0.993 KL: 4.146 KL-reg: 0.399\n",
            "Epoch:  12 Validation Accuracy: 0.994\n",
            "   Loss: 4.299 Accuracy: 0.993 KL: 4.175 KL-reg: 0.406\n",
            "   Loss: 4.206 Accuracy: 0.993 KL: 4.202 KL-reg: 0.412\n",
            "   Loss: 4.243 Accuracy: 0.993 KL: 4.227 KL-reg: 0.419\n",
            "   Loss: 4.362 Accuracy: 0.993 KL: 4.251 KL-reg: 0.426\n",
            "   Loss: 4.283 Accuracy: 0.993 KL: 4.274 KL-reg: 0.432\n",
            "Epoch:  13 Validation Accuracy: 0.994\n",
            "   Loss: 4.301 Accuracy: 0.993 KL: 4.295 KL-reg: 0.439\n",
            "   Loss: 4.325 Accuracy: 0.993 KL: 4.315 KL-reg: 0.445\n",
            "   Loss: 4.433 Accuracy: 0.993 KL: 4.335 KL-reg: 0.452\n",
            "   Loss: 4.361 Accuracy: 0.993 KL: 4.356 KL-reg: 0.458\n",
            "   Loss: 4.390 Accuracy: 0.993 KL: 4.377 KL-reg: 0.465\n",
            "Epoch:  14 Validation Accuracy: 0.994\n",
            "   Loss: 4.487 Accuracy: 0.993 KL: 4.401 KL-reg: 0.471\n",
            "   Loss: 4.438 Accuracy: 0.993 KL: 4.424 KL-reg: 0.478\n",
            "   Loss: 4.462 Accuracy: 0.993 KL: 4.446 KL-reg: 0.484\n",
            "   Loss: 4.478 Accuracy: 0.993 KL: 4.470 KL-reg: 0.491\n",
            "   Loss: 4.623 Accuracy: 0.993 KL: 4.493 KL-reg: 0.498\n",
            "Epoch:  15 Validation Accuracy: 0.994\n",
            "   Loss: 4.518 Accuracy: 0.993 KL: 4.515 KL-reg: 0.504\n",
            "   Loss: 4.545 Accuracy: 0.993 KL: 4.536 KL-reg: 0.511\n",
            "   Loss: 4.568 Accuracy: 0.993 KL: 4.557 KL-reg: 0.517\n",
            "   Loss: 4.585 Accuracy: 0.993 KL: 4.577 KL-reg: 0.524\n",
            "   Loss: 4.600 Accuracy: 0.993 KL: 4.596 KL-reg: 0.530\n",
            "Epoch:  16 Validation Accuracy: 0.994\n",
            "   Loss: 4.618 Accuracy: 0.993 KL: 4.614 KL-reg: 0.537\n",
            "   Loss: 4.675 Accuracy: 0.993 KL: 4.632 KL-reg: 0.543\n",
            "   Loss: 4.659 Accuracy: 0.993 KL: 4.648 KL-reg: 0.550\n",
            "   Loss: 4.672 Accuracy: 0.993 KL: 4.663 KL-reg: 0.556\n",
            "   Loss: 4.862 Accuracy: 0.993 KL: 4.677 KL-reg: 0.563\n",
            "Epoch:  17 Validation Accuracy: 0.994\n",
            "   Loss: 4.695 Accuracy: 0.993 KL: 4.693 KL-reg: 0.570\n",
            "   Loss: 4.763 Accuracy: 0.993 KL: 4.711 KL-reg: 0.576\n",
            "   Loss: 4.774 Accuracy: 0.993 KL: 4.727 KL-reg: 0.583\n",
            "   Loss: 4.758 Accuracy: 0.993 KL: 4.743 KL-reg: 0.589\n",
            "   Loss: 4.767 Accuracy: 0.993 KL: 4.760 KL-reg: 0.596\n",
            "Epoch:  18 Validation Accuracy: 0.994\n",
            "   Loss: 4.841 Accuracy: 0.993 KL: 4.783 KL-reg: 0.602\n",
            "   Loss: 4.820 Accuracy: 0.993 KL: 4.808 KL-reg: 0.609\n",
            "   Loss: 4.847 Accuracy: 0.993 KL: 4.832 KL-reg: 0.615\n",
            "   Loss: 4.910 Accuracy: 0.993 KL: 4.855 KL-reg: 0.622\n",
            "   Loss: 5.032 Accuracy: 0.993 KL: 4.878 KL-reg: 0.628\n",
            "Epoch:  19 Validation Accuracy: 0.994\n",
            "   Loss: 5.013 Accuracy: 0.993 KL: 4.901 KL-reg: 0.635\n",
            "   Loss: 4.936 Accuracy: 0.993 KL: 4.925 KL-reg: 0.642\n",
            "   Loss: 4.996 Accuracy: 0.993 KL: 4.948 KL-reg: 0.648\n",
            "   Loss: 5.111 Accuracy: 0.993 KL: 4.970 KL-reg: 0.655\n",
            "   Loss: 5.000 Accuracy: 0.993 KL: 4.992 KL-reg: 0.661\n",
            "Epoch:  20 Validation Accuracy: 0.994\n",
            "   Loss: 5.070 Accuracy: 0.993 KL: 5.014 KL-reg: 0.668\n",
            "   Loss: 5.042 Accuracy: 0.993 KL: 5.035 KL-reg: 0.674\n",
            "   Loss: 5.228 Accuracy: 0.993 KL: 5.056 KL-reg: 0.681\n",
            "   Loss: 5.131 Accuracy: 0.993 KL: 5.078 KL-reg: 0.687\n",
            "   Loss: 5.191 Accuracy: 0.993 KL: 5.099 KL-reg: 0.694\n",
            "Epoch:  21 Validation Accuracy: 0.994\n",
            "   Loss: 5.239 Accuracy: 0.993 KL: 5.120 KL-reg: 0.700\n",
            "   Loss: 5.346 Accuracy: 0.993 KL: 5.144 KL-reg: 0.707\n",
            "   Loss: 5.253 Accuracy: 0.993 KL: 5.168 KL-reg: 0.714\n",
            "   Loss: 5.202 Accuracy: 0.993 KL: 5.192 KL-reg: 0.720\n",
            "   Loss: 5.224 Accuracy: 0.993 KL: 5.216 KL-reg: 0.727\n",
            "Epoch:  22 Validation Accuracy: 0.994\n",
            "   Loss: 5.293 Accuracy: 0.993 KL: 5.240 KL-reg: 0.733\n",
            "   Loss: 5.271 Accuracy: 0.993 KL: 5.263 KL-reg: 0.740\n",
            "   Loss: 5.295 Accuracy: 0.993 KL: 5.287 KL-reg: 0.746\n",
            "   Loss: 5.317 Accuracy: 0.993 KL: 5.309 KL-reg: 0.753\n",
            "   Loss: 5.338 Accuracy: 0.993 KL: 5.332 KL-reg: 0.759\n",
            "   Loss: 5.371 Accuracy: 0.993 KL: 5.354 KL-reg: 0.766\n",
            "Epoch:  23 Validation Accuracy: 0.994\n",
            "   Loss: 5.395 Accuracy: 0.993 KL: 5.376 KL-reg: 0.772\n",
            "   Loss: 5.401 Accuracy: 0.993 KL: 5.397 KL-reg: 0.779\n",
            "   Loss: 5.425 Accuracy: 0.993 KL: 5.416 KL-reg: 0.785\n",
            "   Loss: 5.470 Accuracy: 0.993 KL: 5.436 KL-reg: 0.792\n",
            "   Loss: 5.458 Accuracy: 0.993 KL: 5.456 KL-reg: 0.799\n",
            "Epoch:  24 Validation Accuracy: 0.994\n",
            "   Loss: 5.483 Accuracy: 0.993 KL: 5.475 KL-reg: 0.805\n",
            "   Loss: 5.505 Accuracy: 0.993 KL: 5.493 KL-reg: 0.812\n",
            "   Loss: 5.602 Accuracy: 0.993 KL: 5.511 KL-reg: 0.818\n",
            "   Loss: 5.538 Accuracy: 0.993 KL: 5.528 KL-reg: 0.825\n",
            "   Loss: 5.608 Accuracy: 0.993 KL: 5.545 KL-reg: 0.831\n",
            "Epoch:  25 Validation Accuracy: 0.994\n",
            "   Loss: 5.573 Accuracy: 0.993 KL: 5.562 KL-reg: 0.838\n",
            "   Loss: 5.685 Accuracy: 0.993 KL: 5.578 KL-reg: 0.844\n",
            "   Loss: 5.606 Accuracy: 0.993 KL: 5.594 KL-reg: 0.851\n",
            "   Loss: 5.697 Accuracy: 0.993 KL: 5.609 KL-reg: 0.857\n",
            "   Loss: 5.702 Accuracy: 0.993 KL: 5.623 KL-reg: 0.864\n",
            "Epoch:  26 Validation Accuracy: 0.994\n",
            "   Loss: 5.649 Accuracy: 0.993 KL: 5.638 KL-reg: 0.871\n",
            "   Loss: 5.661 Accuracy: 0.993 KL: 5.653 KL-reg: 0.877\n",
            "   Loss: 5.751 Accuracy: 0.993 KL: 5.666 KL-reg: 0.884\n",
            "   Loss: 5.684 Accuracy: 0.993 KL: 5.679 KL-reg: 0.890\n",
            "   Loss: 5.749 Accuracy: 0.993 KL: 5.692 KL-reg: 0.897\n",
            "Epoch:  27 Validation Accuracy: 0.994\n",
            "   Loss: 5.715 Accuracy: 0.993 KL: 5.704 KL-reg: 0.903\n",
            "   Loss: 5.719 Accuracy: 0.993 KL: 5.716 KL-reg: 0.910\n",
            "   Loss: 5.790 Accuracy: 0.993 KL: 5.728 KL-reg: 0.916\n",
            "   Loss: 5.743 Accuracy: 0.993 KL: 5.738 KL-reg: 0.923\n",
            "   Loss: 5.756 Accuracy: 0.993 KL: 5.749 KL-reg: 0.929\n",
            "Epoch:  28 Validation Accuracy: 0.994\n",
            "   Loss: 5.813 Accuracy: 0.993 KL: 5.761 KL-reg: 0.936\n",
            "   Loss: 5.792 Accuracy: 0.993 KL: 5.776 KL-reg: 0.943\n",
            "   Loss: 5.799 Accuracy: 0.993 KL: 5.789 KL-reg: 0.949\n",
            "   Loss: 5.808 Accuracy: 0.993 KL: 5.803 KL-reg: 0.956\n",
            "   Loss: 5.929 Accuracy: 0.993 KL: 5.815 KL-reg: 0.962\n",
            "Epoch:  29 Validation Accuracy: 0.994\n",
            "   Loss: 5.840 Accuracy: 0.993 KL: 5.828 KL-reg: 0.969\n",
            "   Loss: 5.848 Accuracy: 0.993 KL: 5.840 KL-reg: 0.975\n",
            "   Loss: 5.870 Accuracy: 0.993 KL: 5.852 KL-reg: 0.982\n",
            "   Loss: 5.995 Accuracy: 0.993 KL: 5.864 KL-reg: 0.988\n",
            "   Loss: 5.883 Accuracy: 0.993 KL: 5.876 KL-reg: 0.995\n",
            "Epoch:  30 Validation Accuracy: 0.994\n",
            "   Loss: 6.152 Accuracy: 0.993 KL: 5.879 KL-reg: 1.001\n",
            "   Loss: 6.018 Accuracy: 0.993 KL: 5.855 KL-reg: 1.008\n",
            "   Loss: 5.837 Accuracy: 0.993 KL: 5.831 KL-reg: 1.015\n",
            "   Loss: 5.821 Accuracy: 0.993 KL: 5.807 KL-reg: 1.021\n",
            "   Loss: 5.809 Accuracy: 0.993 KL: 5.785 KL-reg: 1.028\n",
            "Epoch:  31 Validation Accuracy: 0.994\n",
            "   Loss: 5.821 Accuracy: 0.993 KL: 5.763 KL-reg: 1.034\n",
            "   Loss: 5.805 Accuracy: 0.993 KL: 5.741 KL-reg: 1.041\n",
            "   Loss: 5.736 Accuracy: 0.993 KL: 5.718 KL-reg: 1.047\n",
            "   Loss: 5.713 Accuracy: 0.993 KL: 5.696 KL-reg: 1.054\n",
            "   Loss: 5.699 Accuracy: 0.993 KL: 5.673 KL-reg: 1.060\n",
            "Epoch:  32 Validation Accuracy: 0.994\n",
            "   Loss: 5.659 Accuracy: 0.993 KL: 5.650 KL-reg: 1.067\n",
            "   Loss: 5.726 Accuracy: 0.993 KL: 5.627 KL-reg: 1.073\n",
            "   Loss: 5.620 Accuracy: 0.993 KL: 5.605 KL-reg: 1.080\n",
            "   Loss: 5.595 Accuracy: 0.993 KL: 5.582 KL-reg: 1.087\n",
            "   Loss: 5.567 Accuracy: 0.993 KL: 5.560 KL-reg: 1.093\n",
            "Epoch:  33 Validation Accuracy: 0.994\n",
            "   Loss: 5.546 Accuracy: 0.993 KL: 5.537 KL-reg: 1.100\n",
            "   Loss: 5.611 Accuracy: 0.993 KL: 5.516 KL-reg: 1.106\n",
            "   Loss: 5.507 Accuracy: 0.993 KL: 5.494 KL-reg: 1.113\n",
            "   Loss: 5.485 Accuracy: 0.993 KL: 5.471 KL-reg: 1.119\n",
            "   Loss: 5.462 Accuracy: 0.993 KL: 5.449 KL-reg: 1.126\n",
            "   Loss: 5.505 Accuracy: 0.993 KL: 5.427 KL-reg: 1.132\n",
            "Epoch:  34 Validation Accuracy: 0.994\n",
            "   Loss: 5.414 Accuracy: 0.993 KL: 5.406 KL-reg: 1.139\n",
            "   Loss: 5.397 Accuracy: 0.993 KL: 5.384 KL-reg: 1.146\n",
            "   Loss: 5.435 Accuracy: 0.993 KL: 5.362 KL-reg: 1.152\n",
            "   Loss: 5.411 Accuracy: 0.993 KL: 5.341 KL-reg: 1.159\n",
            "   Loss: 5.487 Accuracy: 0.993 KL: 5.319 KL-reg: 1.165\n",
            "Epoch:  35 Validation Accuracy: 0.994\n",
            "   Loss: 5.313 Accuracy: 0.993 KL: 5.297 KL-reg: 1.172\n",
            "   Loss: 5.288 Accuracy: 0.993 KL: 5.275 KL-reg: 1.178\n",
            "   Loss: 5.279 Accuracy: 0.993 KL: 5.253 KL-reg: 1.185\n",
            "   Loss: 5.247 Accuracy: 0.993 KL: 5.235 KL-reg: 1.191\n",
            "   Loss: 5.236 Accuracy: 0.993 KL: 5.225 KL-reg: 1.198\n",
            "Epoch:  36 Validation Accuracy: 0.993\n",
            "   Loss: 10.521 Accuracy: 0.993 KL: 5.216 KL-reg: 1.204\n",
            "   Loss: 5.221 Accuracy: 0.993 KL: 5.207 KL-reg: 1.211\n",
            "   Loss: 5.210 Accuracy: 0.993 KL: 5.198 KL-reg: 1.218\n",
            "   Loss: 5.200 Accuracy: 0.993 KL: 5.190 KL-reg: 1.224\n",
            "   Loss: 5.194 Accuracy: 0.993 KL: 5.182 KL-reg: 1.231\n",
            "Epoch:  37 Validation Accuracy: 0.993\n",
            "   Loss: 5.252 Accuracy: 0.993 KL: 5.173 KL-reg: 1.237\n",
            "   Loss: 5.177 Accuracy: 0.993 KL: 5.165 KL-reg: 1.244\n",
            "   Loss: 5.237 Accuracy: 0.993 KL: 5.157 KL-reg: 1.250\n",
            "   Loss: 5.229 Accuracy: 0.993 KL: 5.148 KL-reg: 1.257\n",
            "   Loss: 5.150 Accuracy: 0.993 KL: 5.140 KL-reg: 1.263\n",
            "Epoch:  38 Validation Accuracy: 0.993\n",
            "   Loss: 5.641 Accuracy: 0.993 KL: 5.132 KL-reg: 1.270\n",
            "   Loss: 5.134 Accuracy: 0.993 KL: 5.124 KL-reg: 1.277\n",
            "   Loss: 5.123 Accuracy: 0.993 KL: 5.115 KL-reg: 1.283\n",
            "   Loss: 5.117 Accuracy: 0.993 KL: 5.108 KL-reg: 1.290\n",
            "   Loss: 5.110 Accuracy: 0.993 KL: 5.101 KL-reg: 1.296\n",
            "Epoch:  39 Validation Accuracy: 0.993\n",
            "   Loss: 5.175 Accuracy: 0.993 KL: 5.094 KL-reg: 1.303\n",
            "   Loss: 5.212 Accuracy: 0.993 KL: 5.087 KL-reg: 1.309\n",
            "   Loss: 5.088 Accuracy: 0.993 KL: 5.079 KL-reg: 1.316\n",
            "   Loss: 5.080 Accuracy: 0.993 KL: 5.072 KL-reg: 1.322\n",
            "   Loss: 5.219 Accuracy: 0.993 KL: 5.064 KL-reg: 1.329\n",
            "Epoch:  40 Validation Accuracy: 0.993\n",
            "   Loss: 5.328 Accuracy: 0.993 KL: 5.057 KL-reg: 1.336\n",
            "   Loss: 5.058 Accuracy: 0.993 KL: 5.049 KL-reg: 1.342\n",
            "   Loss: 5.051 Accuracy: 0.993 KL: 5.042 KL-reg: 1.349\n",
            "   Loss: 5.117 Accuracy: 0.993 KL: 5.034 KL-reg: 1.355\n",
            "   Loss: 5.035 Accuracy: 0.993 KL: 5.027 KL-reg: 1.362\n",
            "Epoch:  41 Validation Accuracy: 0.993\n",
            "   Loss: 5.028 Accuracy: 0.993 KL: 5.020 KL-reg: 1.368\n",
            "   Loss: 5.021 Accuracy: 0.993 KL: 5.013 KL-reg: 1.375\n",
            "   Loss: 5.016 Accuracy: 0.993 KL: 5.009 KL-reg: 1.381\n",
            "   Loss: 5.011 Accuracy: 0.993 KL: 5.003 KL-reg: 1.388\n",
            "   Loss: 5.005 Accuracy: 0.993 KL: 4.997 KL-reg: 1.394\n",
            "Epoch:  42 Validation Accuracy: 0.993\n",
            "   Loss: 4.999 Accuracy: 0.993 KL: 4.991 KL-reg: 1.401\n",
            "   Loss: 4.993 Accuracy: 0.993 KL: 4.985 KL-reg: 1.408\n",
            "   Loss: 4.987 Accuracy: 0.993 KL: 4.979 KL-reg: 1.414\n",
            "   Loss: 4.981 Accuracy: 0.993 KL: 4.973 KL-reg: 1.421\n",
            "   Loss: 5.050 Accuracy: 0.993 KL: 4.967 KL-reg: 1.427\n",
            "Epoch:  43 Validation Accuracy: 0.993\n",
            "   Loss: 4.968 Accuracy: 0.993 KL: 4.961 KL-reg: 1.434\n",
            "   Loss: 5.038 Accuracy: 0.993 KL: 4.955 KL-reg: 1.440\n",
            "   Loss: 5.032 Accuracy: 0.993 KL: 4.948 KL-reg: 1.447\n",
            "   Loss: 4.949 Accuracy: 0.993 KL: 4.942 KL-reg: 1.453\n",
            "   Loss: 4.943 Accuracy: 0.993 KL: 4.936 KL-reg: 1.460\n",
            "Epoch:  44 Validation Accuracy: 0.994\n",
            "   Loss: 4.936 Accuracy: 0.993 KL: 4.929 KL-reg: 1.467\n",
            "   Loss: 4.930 Accuracy: 0.993 KL: 4.923 KL-reg: 1.473\n",
            "   Loss: 4.956 Accuracy: 0.993 KL: 4.916 KL-reg: 1.480\n",
            "   Loss: 4.918 Accuracy: 0.993 KL: 4.910 KL-reg: 1.486\n",
            "   Loss: 5.064 Accuracy: 0.993 KL: 4.904 KL-reg: 1.493\n",
            "Epoch:  45 Validation Accuracy: 0.994\n",
            "   Loss: 5.058 Accuracy: 0.993 KL: 4.897 KL-reg: 1.499\n",
            "   Loss: 4.898 Accuracy: 0.993 KL: 4.891 KL-reg: 1.506\n",
            "   Loss: 4.891 Accuracy: 0.993 KL: 4.884 KL-reg: 1.512\n",
            "   Loss: 5.039 Accuracy: 0.993 KL: 4.878 KL-reg: 1.519\n",
            "   Loss: 4.955 Accuracy: 0.993 KL: 4.871 KL-reg: 1.525\n",
            "   Loss: 4.871 Accuracy: 0.993 KL: 4.864 KL-reg: 1.532\n",
            "Epoch:  46 Validation Accuracy: 0.993\n",
            "   Loss: 4.865 Accuracy: 0.993 KL: 4.858 KL-reg: 1.539\n",
            "   Loss: 4.858 Accuracy: 0.993 KL: 4.851 KL-reg: 1.545\n",
            "   Loss: 4.851 Accuracy: 0.993 KL: 4.844 KL-reg: 1.552\n",
            "   Loss: 4.922 Accuracy: 0.993 KL: 4.837 KL-reg: 1.558\n",
            "   Loss: 4.838 Accuracy: 0.993 KL: 4.831 KL-reg: 1.565\n",
            "Epoch:  47 Validation Accuracy: 0.994\n",
            "   Loss: 4.831 Accuracy: 0.993 KL: 4.824 KL-reg: 1.571\n",
            "   Loss: 4.824 Accuracy: 0.993 KL: 4.817 KL-reg: 1.578\n",
            "   Loss: 22.526 Accuracy: 0.993 KL: 4.811 KL-reg: 1.584\n",
            "   Loss: 4.888 Accuracy: 0.993 KL: 4.804 KL-reg: 1.591\n",
            "   Loss: 4.804 Accuracy: 0.993 KL: 4.797 KL-reg: 1.598\n",
            "Epoch:  48 Validation Accuracy: 0.994\n",
            "   Loss: 4.952 Accuracy: 0.993 KL: 4.790 KL-reg: 1.604\n",
            "   Loss: 4.791 Accuracy: 0.993 KL: 4.784 KL-reg: 1.611\n",
            "   Loss: 4.939 Accuracy: 0.993 KL: 4.777 KL-reg: 1.617\n",
            "   Loss: 4.777 Accuracy: 0.993 KL: 4.770 KL-reg: 1.624\n",
            "   Loss: 4.770 Accuracy: 0.993 KL: 4.764 KL-reg: 1.630\n",
            "Epoch:  49 Validation Accuracy: 0.994\n",
            "   Loss: 4.763 Accuracy: 0.993 KL: 4.757 KL-reg: 1.637\n",
            "   Loss: 4.835 Accuracy: 0.993 KL: 4.750 KL-reg: 1.643\n",
            "   Loss: 4.750 Accuracy: 0.993 KL: 4.743 KL-reg: 1.650\n",
            "   Loss: 4.743 Accuracy: 0.993 KL: 4.736 KL-reg: 1.656\n",
            "   Loss: 4.891 Accuracy: 0.993 KL: 4.729 KL-reg: 1.663\n",
            "Epoch:  50 Validation Accuracy: 0.994\n"
          ]
        }
      ],
      "source": [
        "INITIAL_LEARNING_RATE = 0.001\n",
        "EPOCHS = 50\n",
        "\n",
        "assert (EPOCHS > 0)\n",
        "\n",
        "logits = model(series)\n",
        "loss, kl, kl_reg, labels_distribution = loss_fn(labels, logits)\n",
        "\n",
        "# Build metrics for evaluation. Predictions are formed from a single forward\n",
        "# pass of the probabilistic layers. They are cheap but noisy\n",
        "# predictions.\n",
        "predictions = tf.argmax(input=logits, axis=1)\n",
        "with tf.compat.v1.name_scope(\"train\"):\n",
        "    train_accuracy, train_accuracy_update_op = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predictions)\n",
        "    opt = tf.compat.v1.train.AdamOptimizer(INITIAL_LEARNING_RATE)\n",
        "    train_op = opt.minimize(loss)\n",
        "    update_step_op = tf.compat.v1.assign(t, t + 1)\n",
        "\n",
        "with tf.compat.v1.name_scope(\"valid\"):\n",
        "    valid_accuracy, valid_accuracy_update_op = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predictions)\n",
        "\n",
        "init_op = tf.group(tf.compat.v1.global_variables_initializer(), tf.compat.v1.local_variables_initializer())\n",
        "\n",
        "stream_vars_valid = [\n",
        "    v for v in tf.compat.v1.local_variables() if \"valid/\" in v.name\n",
        "]\n",
        "reset_valid_op = tf.compat.v1.variables_initializer(stream_vars_valid)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "\n",
        "    # Run the training loop\n",
        "    train_handle = sess.run(training_iterator.string_handle())\n",
        "    heldout_handle = sess.run(heldout_iterator.string_handle())\n",
        "    training_steps = EPOCHS * BATCHES_PER_EPOCH\n",
        "    \n",
        "    for step in range(training_steps):\n",
        "        _ = sess.run([train_op, train_accuracy_update_op, update_step_op], feed_dict={handle: train_handle})\n",
        "\n",
        "        # Manually print the frequency\n",
        "        if step % (BATCHES_PER_EPOCH // 5) == 0:\n",
        "            loss_value, accuracy_value, kl_value, kl_reg_value = sess.run([loss, train_accuracy, kl, kl_reg], feed_dict={handle: train_handle})\n",
        "            print(\"   Loss: {:.3f} Accuracy: {:.3f} KL: {:.3f} KL-reg: {:.3f}\".format(loss_value, accuracy_value, kl_value, kl_reg_value))\n",
        "\n",
        "        if (step + 1) % BATCHES_PER_EPOCH == 0:\n",
        "            # Calculate validation accuracy\n",
        "            for _ in range(TEST_BATCHES_PER_EPOCH):\n",
        "                sess.run(valid_accuracy_update_op, feed_dict={handle: heldout_handle})\n",
        "            \n",
        "            valid_value = sess.run(valid_accuracy, feed_dict={handle: heldout_handle})\n",
        "            print(\"Epoch: {:>3d} Validation Accuracy: {:.3f}\".format((step + 1) // BATCHES_PER_EPOCH, valid_value))\n",
        "\n",
        "            sess.run(reset_valid_op)\n",
        "            \n",
        "    model.save_weights(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ml9cWK8j0vEU"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p40qKgiIIVNd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\Anaconda\\envs\\graphAD\\lib\\site-packages\\keras\\engine\\training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ],
      "source": [
        "NUM_MONTE_CARLO = 20\n",
        "\n",
        "model.load_weights(MODEL_PATH)\n",
        "\n",
        "mc_counts = np.zeros((TEST_COUNT, 2))\n",
        "x = np.expand_dims(x_test, -1)\n",
        "sample_index = np.arange(TEST_COUNT)\n",
        "\n",
        "for i in range(NUM_MONTE_CARLO):\n",
        "    y_pred = np.argmax(model.predict(x), axis=1)\n",
        "    mc_counts[sample_index, y_pred] += 1\n",
        "    \n",
        "y_pred = np.argmax(mc_counts, axis=1)\n",
        "y_prob = mc_counts[sample_index, y_pred] / NUM_MONTE_CARLO\n",
        "\n",
        "y_prob_correct = y_prob[y_pred == y_test]\n",
        "y_prob_mis = y_prob[y_pred != y_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWh_nMZN9J0N"
      },
      "source": [
        "### Check probability estimates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ggvEGluM9TEw"
      },
      "source": [
        "### Compute metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TeV6NtwnP0Lm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      3658\n",
            "           1       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.99      3680\n",
            "   macro avg       0.50      0.50      0.50      3680\n",
            "weighted avg       0.99      0.99      0.99      3680\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\Anaconda\\envs\\graphAD\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Dell\\Anaconda\\envs\\graphAD\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Dell\\Anaconda\\envs\\graphAD\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import sklearn.metrics as skm\n",
        "import seaborn\n",
        "\n",
        "# Classification report\n",
        "report = skm.classification_report(y_test, y_pred)\n",
        "print(report)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = skm.confusion_matrix(y_test, y_pred)\n",
        "seaborn.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MnQeNtCkV3Uv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "x2Q8Cy8HZ8dB"
      ],
      "name": "BayesClassifierECG-v1.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
